{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi GPU Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# fixed random seed to have consistent results\n",
    "np.random.seed(123)\n",
    "\n",
    "train_dir = \"../Sample3/data/train\"\n",
    "val_dir = \"../Sample3/data/test\"\n",
    "epochs = 5\n",
    "nb_GPU = 4\n",
    "batch_size = 30 * nb_GPU\n",
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 300\n",
    "img_width, img_height = 299, 299 # fixed size for InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is simple. Load one high quality pre-trained network and remove last layer that is supposed to do final prediction. Replace that layer with a final layer doing the prediction for our two classes and train only the weights for the added layer. As long as you are using a network trained for similar problem like recognising animals or birds, the first layers before prediction are already trained to understand features and representations that would probably apply well to dogs and cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# data prep\n",
    "train_datagen =  ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we will grab Inception V3 network with its pre-trained weights simply remove the last layer and add our own last `Dense` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # setup model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) # include_top=False excludes final fully connected layer\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x) # this layer prevents overfitting and generally recommended between conv layers and dense ones\n",
    "    x = Dense(1024, activation='relu')(x) #new FC layer\n",
    "    prediction = Dense(1, activation='sigmoid')(x) # new sigmoid layer\n",
    "    model = Model(inputs=base_model.input, outputs=prediction)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the model parallel\n",
    "multi_gpu_model = multi_gpu_model(model, gpus = nb_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gpu_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25/25 [==============================] - 71s 3s/step - loss: 0.4468 - acc: 0.8270 - val_loss: 0.0410 - val_acc: 0.9900\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 18s 737ms/step - loss: 0.0973 - acc: 0.9647 - val_loss: 0.0371 - val_acc: 0.9967\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 18s 738ms/step - loss: 0.0696 - acc: 0.9723 - val_loss: 0.0463 - val_acc: 0.9967\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 18s 734ms/step - loss: 0.0656 - acc: 0.9767 - val_loss: 0.0971 - val_acc: 0.9567\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 18s 726ms/step - loss: 0.0836 - acc: 0.9707 - val_loss: 0.0939 - val_acc: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46ea8b6f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us do the training\n",
    "multi_gpu_model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch = math.ceil(nb_train_samples / batch_size),    \n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = math.ceil(nb_validation_samples/batch_size),\n",
    "    workers=24, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 2 classes.\n",
      "test acc: 0.9632936503205981\n",
      "test loss: 0.0941497687072981\n"
     ]
    }
   ],
   "source": [
    "test_datagen1 = ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input \n",
    ")\n",
    "\n",
    "test_generator1 = test_datagen1.flow_from_directory(val_dir, \n",
    "                                                    target_size=(img_width, img_height), \n",
    "                                                    batch_size=batch_size,  class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = multi_gpu_model.evaluate_generator(test_generator1, steps=50)\n",
    "print('test acc:', test_acc)\n",
    "print('test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MultiGPU.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
