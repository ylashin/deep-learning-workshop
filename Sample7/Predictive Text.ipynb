{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    doc = doc.replace('\\n\\n', '\\n').replace('\\n\\n', '\\n').replace('\\n\\n', '\\n')    \n",
    "    tokens = doc.split() # split into tokens by white space    \n",
    "    table = str.maketrans('', '', string.punctuation) # remove punctuation from each token\n",
    "    tokens = [w.translate(table) for w in tokens]    \n",
    "    tokens = [word for word in tokens if word.isalpha()] # remove remaining tokens that are not alphabetic    \n",
    "    tokens = [word.lower() for word in tokens] # make lower case\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Old Sea-dog at the Admiral Benbow\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = open('treasure-island.txt', encoding=\"utf8\").read()\n",
    "print(doc[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['old', 'seadog', 'at', 'the', 'admiral', 'benbow', 'squire', 'trelawney', 'dr', 'livesey', 'and', 'the', 'rest', 'of', 'these', 'gentlemen', 'having', 'asked', 'me', 'to']\n",
      "Total Tokens: 65486\n",
      "Unique Tokens: 6371\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:20])\n",
    "print(\"Total Tokens: \" + str(len(tokens)))\n",
    "print(\"Unique Tokens: \" + str(len(set(tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 65435\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "# organize into sequences of tokens\n",
    "length = SEQUENCE_LENGTH + 1 # the one here is the next token which is the label in our case\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    seq = tokens[i-length:i]\n",
    "    line = ' '.join(seq)\n",
    "    sequences.append(line)\n",
    "    \n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6372\n"
     ]
    }
   ],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "sequences = tokenizer.texts_to_sequences(sequences)\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65435, 50)\n",
      "(65435, 6372)\n",
      "[  76 6371   21    1  402  442   94  319  209  190    2    1  251    4\n",
      "  126  490  566  220   23    6 3064   57    1  259 6369   67  208  119\n",
      "   38    1  745    6    1  198  744  188   82   20    1 1341    4    1\n",
      "  119    2   10  103 1143   40   47   75]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 50, 50)            318600    \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 128)               68736     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              264192    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6372)              13056228  \n",
      "=================================================================\n",
      "Total params: 13,707,756\n",
      "Trainable params: 13,707,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH))\n",
    "model.add(GRU(128)) #, return_sequences=True\n",
    "#model.add(GRU(128))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.01), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "65435/65435 [==============================] - 21s 319us/step - loss: 6.5964 - acc: 0.0744\n",
      "Epoch 2/20\n",
      "65435/65435 [==============================] - 20s 303us/step - loss: 5.6609 - acc: 0.1255\n",
      "Epoch 3/20\n",
      "65435/65435 [==============================] - 20s 299us/step - loss: 5.1981 - acc: 0.1495\n",
      "Epoch 4/20\n",
      "65435/65435 [==============================] - 20s 303us/step - loss: 4.7885 - acc: 0.1698\n",
      "Epoch 5/20\n",
      "65435/65435 [==============================] - 20s 299us/step - loss: 4.3901 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "65435/65435 [==============================] - 19s 286us/step - loss: 3.9684 - acc: 0.2185\n",
      "Epoch 7/20\n",
      "65435/65435 [==============================] - 17s 257us/step - loss: 3.5634 - acc: 0.2528\n",
      "Epoch 8/20\n",
      "65435/65435 [==============================] - 16s 242us/step - loss: 3.1602 - acc: 0.3042\n",
      "Epoch 9/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 2.7885 - acc: 0.3594\n",
      "Epoch 10/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 2.4632 - acc: 0.4157\n",
      "Epoch 11/20\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 2.1877 - acc: 0.4654\n",
      "Epoch 12/20\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 1.9501 - acc: 0.5123\n",
      "Epoch 13/20\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 1.7938 - acc: 0.5415\n",
      "Epoch 14/20\n",
      "65435/65435 [==============================] - 16s 238us/step - loss: 1.6291 - acc: 0.5755\n",
      "Epoch 15/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 1.5008 - acc: 0.6024\n",
      "Epoch 16/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 1.3877 - acc: 0.6284\n",
      "Epoch 17/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 1.2899 - acc: 0.6497\n",
      "Epoch 18/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 1.2128 - acc: 0.6693\n",
      "Epoch 19/20\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 1.1227 - acc: 0.6901\n",
      "Epoch 20/20\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 1.0623 - acc: 0.7061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b46cd3c50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, Y, batch_size= 512, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 1.0285 - acc: 0.7116\n",
      "Epoch 2/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 1.0114 - acc: 0.7187\n",
      "Epoch 3/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 0.9370 - acc: 0.7373\n",
      "Epoch 4/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 0.9168 - acc: 0.7435\n",
      "Epoch 5/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 0.8982 - acc: 0.7456\n",
      "Epoch 6/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 0.8662 - acc: 0.7557\n",
      "Epoch 7/10\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 0.8420 - acc: 0.7643\n",
      "Epoch 8/10\n",
      "65435/65435 [==============================] - 16s 240us/step - loss: 0.7918 - acc: 0.7768\n",
      "Epoch 9/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 0.7849 - acc: 0.7794\n",
      "Epoch 10/10\n",
      "65435/65435 [==============================] - 16s 239us/step - loss: 0.7763 - acc: 0.7809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b1c152048>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, Y, batch_size= 512, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Sample7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = tokenizer.word_index\n",
    "index2word = dict((c, w) for w, c in word2index.items()) # index2word is available directly on tokenizer on new keras versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=SEQUENCE_LENGTH, truncating='pre')\n",
    "\n",
    "        prediction = model.predict_classes(encoded, verbose=0)\n",
    "        \n",
    "        # map predicted word index to word        \n",
    "        out_word = index2word[prediction[0]]\n",
    "      \n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = \"It was a dark night near the scary shore and the ships were resting as giant monsters we had to move slowly and take care of each other as there was lots of injuries the wind has been in our favour\"\n",
    "print(len(seed_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we began to scramble out of a bribe want none of your own sir you have the last good as for that lot and their council mark me theyre outright fools and cowards ill save your lifeif so do i believe this crew youll believe and i must know where is one can youll up and i dont like an echo than he sailed with of it was said i would go back to captain kidds anchorage ran from the twopeaked hill upon the captain and we could fight for the ship but i was determined to go down the squire and dr livesey were seated on either a harbourbar my mother pulled it up with impatience and there lay before us the last things in the centre after one lad went to the echoes and one of the cocks with his hat having fallen against a big seaman obrien carried his cutlass did you may suppose that he took it a deal more rum and i dare say true i had gone up to execution dock by thunder so do and it why its here englands men will you ring that bell mr dance must have shown for course\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(seed_text, 200)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def saveDictionary(dict, fileName) :\n",
    "    f = open(fileName, \"w\", newline='')\n",
    "    w = csv.writer(f)\n",
    "    for key, val in dict.items():\n",
    "        w.writerow([key, val])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictionary(word2index, \"word2index.csv\")\n",
    "saveDictionary(index2word, \"index2word.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
